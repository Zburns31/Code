{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Setup\n",
    "\n",
    "Best Practices: https://www.kaggle.com/jpmiller/some-best-practices-for-analytics-reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import re\n",
    "import shap\n",
    "\n",
    "from math import sqrt\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (roc_curve, \n",
    "                             roc_auc_score, \n",
    "                             precision_recall_curve, \n",
    "                             f1_score, \n",
    "                             average_precision_score, \n",
    "                             confusion_matrix, \n",
    "                             accuracy_score, \n",
    "                             mean_squared_error,\n",
    "                             mean_absolute_error,\n",
    "                             make_scorer,\n",
    "                             r2_score\n",
    "                            )\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, validation_curve, KFold\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = ''\n",
    "\n",
    "df = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Profile Report\n",
    "df = ProfileReport(df=, title=\"Pandas Profile\")\n",
    "df.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "-----------------\n",
    "\n",
    "Time allocated should be ~15 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting digits from a string column\n",
    "df['col'] = df['col'].str.split('.').apply(lambda x: int(''.join(filter(str.isdigit, x[0]))))\n",
    "\n",
    "# check for string null values or characters\n",
    "df = df[(df['col'].notnull()) |\n",
    "        (df['col'].str.contains('-'))\n",
    "]\n",
    "\n",
    "# Replace multiple values in a string column. Regex = True\n",
    "df['col'] = df['df'].replace(['{', '}', '\"', '\"'], '', regex=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Column Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_translation_missing_val(list_col):\n",
    "    return [item for item in list_col if not 'translation missing' in item]\n",
    "\n",
    "df['col'] = df['col'].apply(remove_translation_missing_val)\n",
    "\n",
    "# Create a set of items from a column of lists\n",
    "amenities = set(itertools.chain.from_iterable(listings.amenities))\n",
    "amenities = [item for item in amenities if item] # keep non-null values\n",
    "\n",
    "# create columns based on values inside of list\n",
    "for amenity in amenities:\n",
    "    df[f\"amenity_{amenity}\"] = listings.apply(lambda x: 1 if amenity in x['amenities'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin columns into groups\n",
    "bins = [num for num in range(0, 1001, 50)]\n",
    "df['col'] = pd.cut(df['col'], bins=bins)\n",
    "\n",
    "# If,else functions on columns\n",
    "df['col'] = np.where(df['col'].isnull(), value, df['col'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Type Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['neighbourhood', 'property_type', 'room_type', 'bed_type', 'cancellation_policy']\n",
    "\n",
    "df[cat_cols] = df[cat_cols].apply(lambda x: x.astype('category'), axis =1)[cat_cols]\n",
    "df[cat_cols].info(verbose=True)\n",
    "\n",
    "review_scores_feats = [col for col in listings.columns if 'review_scores' in col]\n",
    "amenity_feats = [col for col in listings.columns if 'amenity_' in col]\n",
    "\n",
    "num_cols = (['accommodates', 'bathrooms', 'bedrooms', 'beds', 'square_feet', \n",
    "             'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people',\n",
    "             'minimum_nights', 'maximum_nights', 'number_of_reviews', \n",
    "             'number_of_reviews_ltm', 'reviews_per_month', 'num_amenities'] +\n",
    "             review_scores_feats + amenity_feats\n",
    "           \n",
    "           )\n",
    "\n",
    "for col in num_cols:\n",
    "    listings[col] = pd.to_numeric(listings[col])\n",
    "    \n",
    "\n",
    "for col in cat_cols:\n",
    "    listings[f\"{col}_cat\"] = listings[col].astype('category').cat.codes\n",
    "\n",
    "listings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "------------\n",
    "\n",
    "Time allocated should be ~15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "\n",
    "apartments = listings[listings['property_type']=='Apartment'].sort_values(by='price_range')\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=apartments['price_range'].astype('str'),\n",
    "    histnorm='percent',\n",
    "    name='Distribution of Apartment Listing Prices by Bucket' # name used in legend and hover labels\n",
    "))\n",
    "\n",
    "\n",
    "fig.update_layout(title='Distribution of Apartment Listings by Price', \n",
    "                  barmode='group', \n",
    "                  xaxis_tickangle=-45,\n",
    "                  xaxis_title=\"Price Bucket\",\n",
    "                  yaxis_title=\"Frequency\"\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram with multiple plots\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1)\n",
    "\n",
    "fig.append_trace(go.Histogram(\n",
    "    x=listings['price'],\n",
    "    histnorm='percent',\n",
    "    name='Distribution of Price' # name used in legend and hover labels\n",
    "), 1, 1)\n",
    "\n",
    "fig.append_trace(go.Histogram(\n",
    "    x=np.log(listings['price']),\n",
    "    histnorm='percent',\n",
    "    name='Log Distribution of Price' # name used in legend and hover labels\n",
    "), 2, 1)\n",
    "\n",
    "fig.update_layout(title='Distribution of Price',\n",
    "                  barmode='overlay',\n",
    "                  xaxis_title=\"Price\",\n",
    "                  yaxis_title=\"Percent\"\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal/Normal Bar chart with average line\n",
    "\n",
    "neighbourhood_frequency = listings['neighbourhood'].value_counts()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "              x=neighbourhood_frequency,\n",
    "              y=neighbourhood_frequency.index,\n",
    "              name='Neighbourhoods',\n",
    "              orientation='h',\n",
    "              marker_color=plotly.colors.sequential.Rainbow[4]\n",
    "))\n",
    "\n",
    "fig.add_shape(\n",
    "        go.layout.Shape(type='line', xref='x', yref='y',\n",
    "                        x0=neighbourhood_frequency.mean(), \n",
    "                        y0=0, \n",
    "                        x1=neighbourhood_frequency.mean(), \n",
    "                        y1=len(neighbourhood_frequency), \n",
    "                        line={'dash': 'dash'})\n",
    ")\n",
    "\n",
    "# Add annotation with text for the average line\n",
    "# fig.add_annotation(text=f\"Average Number of Listings == {round(neighbourhood_frequency.mean())}\", \n",
    "#                    x=\"428\", \n",
    "#                    y=\"Oud-West\", showarrow=True, arrowhead=1\n",
    "# )\n",
    "\n",
    "fig.update_layout(title='Number of Listings by Neighbourhood', \n",
    "                  xaxis_tickangle=-45,\n",
    "                  xaxis_title=\"Neighbourhood\",\n",
    "                  yaxis_title=\"Number of Listings\",\n",
    "                  autosize=False,\n",
    "                  height=1000,\n",
    "                  width=1000,\n",
    "                  yaxis={'categoryorder':'total ascending'}\n",
    ")\n",
    "\n",
    "print(f\"The average number of listings by neighbourhood in Amsterdam is: {round(neighbourhood_frequency.mean())}\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart with multiple traces\n",
    "\n",
    "room_types = (listings[['room_type', 'price_range']]\n",
    "              .groupby(['room_type', 'price_range'])\n",
    "              .size()\n",
    "              .reset_index()\n",
    "              .rename(columns={0:'count'})\n",
    ")\n",
    "\n",
    "\n",
    "traces = []\n",
    "for room_type in listings['room_type'].unique():\n",
    "    filtered_df = room_types[room_types['room_type']==room_type]\n",
    "\n",
    "    trace = go.Bar(x=filtered_df[\"price_range\"].astype('str'),\n",
    "                   y=filtered_df[\"count\"],\n",
    "                   name=room_type\n",
    "                  )\n",
    "    traces.append(trace)\n",
    "    \n",
    "layout = go.Layout(title='Distribution of Room Types by Price', \n",
    "                   barmode='group', \n",
    "                   xaxis_tickangle=-45,\n",
    "                   xaxis_title=\"Price Bucket\",\n",
    "                   yaxis_title=\"Frequency\"\n",
    "                  )\n",
    "\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot with Multiple traces\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "              x=[num for num in range(10, 200, 20)],\n",
    "              y=[np.mean(fold) for fold in train_scores],\n",
    "              name='Train MAE',\n",
    "              mode='lines+markers',\n",
    "              marker_color=plotly.colors.sequential.Jet[2]\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "              x=[num for num in range(10, 200, 20)],\n",
    "              y=[np.mean(fold) for fold in test_scores],\n",
    "              name='Test MAE',\n",
    "              mode='lines+markers',\n",
    "              marker_color=plotly.colors.sequential.Jet[4]\n",
    "))\n",
    "\n",
    "fig.update_layout(title='Validation Curve: Number of Estimators', \n",
    "                  xaxis_tickangle=-45,\n",
    "                  xaxis_title=\"Number of Estimators\",\n",
    "                  yaxis_title=\"CV MAE\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap\n",
    "\n",
    "cols = ['accommodates', 'bathrooms', 'bedrooms', 'beds', #'square_feet', \n",
    "        'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people',\n",
    "        'minimum_nights', 'maximum_nights', 'number_of_reviews', \n",
    "        'number_of_reviews_ltm', 'reviews_per_month', 'num_amenities',\n",
    "        'price'] + [col for col in listings.columns if '_cat' in col]\n",
    "\n",
    "corr_plot = listings[cols].corr()\n",
    "\n",
    "# Code to only keep bottom half of the correlation map\n",
    "# mask = np.zeros(corr_plot.shape, dtype=bool)\n",
    "# mask[np.triu_indices(len(mask))] = True\n",
    "mask = None\n",
    "\n",
    "fig = plt.figure(figsize=(15,12))\n",
    "palette = sns.diverging_palette(20, 220, n=256)\n",
    "sns.heatmap(corr_plot, \n",
    "            annot=True, \n",
    "            fmt=\".2f\", \n",
    "            vmin = -1, \n",
    "            vmax = 1, \n",
    "            center = 0, \n",
    "            mask=mask, \n",
    "            cmap=palette, \n",
    "            robust=True,\n",
    "            linewidths=.5\n",
    ")\n",
    "plt.title(\"Correlation Matrix\",size=15, weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot\n",
    "pairplot_cols = ['accommodates', 'bathrooms', 'bedrooms', 'beds', #'square_feet', \n",
    "                  'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people',\n",
    "                  'minimum_nights', 'maximum_nights', 'number_of_reviews', \n",
    "                  'number_of_reviews_ltm', 'reviews_per_month', 'num_amenities','price']\n",
    "\n",
    "sns.pairplot(listings[pairplot_cols], corner = True, height=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline & Model\n",
    "--------------\n",
    "\n",
    "Time allocated should be ~15 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFReg = RandomForestRegressor(random_state = 42)\n",
    "\n",
    "# Need label of step in pipeline when using Pipeline() methods\n",
    "# https://stackoverflow.com/questions/48271342/invalid-parameter-clf-for-estimator-pipeline-in-sklearn\n",
    "param_dist = {\"regressor__criterion\": [\"mse\"],\n",
    "              \"regressor__n_estimators\": [100, 200],\n",
    "#               \"regressor__min_samples_split\": [10, 20],\n",
    "              \"regressor__max_depth\": [3, 6, 8],\n",
    "#               \"regressor__min_samples_leaf\": [20, 40],\n",
    "#               \"regressor__max_leaf_nodes\": [5, 20],\n",
    "}\n",
    "\n",
    "cat_cols_indx = [f\"{col}_cat\" for col in cat_cols]\n",
    "\n",
    "\n",
    "# def create_ml_pipeline(df, num_cols, cat_cols, target_col, model, parameters, test_ratio = 0.3):\n",
    "    \n",
    "listings[num_cols].fillna(value = 0, inplace = True)\n",
    "# Imputing categorical values\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', imputer),\n",
    "    ('regressor', RFReg)\n",
    "])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(listings[num_cols + cat_cols_indx],\n",
    "                                                    listings[target],\n",
    "                                                    test_size= 0.3,\n",
    "                                                    shuffle = True,\n",
    "                                                    random_state = 42\n",
    "                                                   )\n",
    "\n",
    "scorer = make_scorer(mean_absolute_error)\n",
    "#     scoring = {'mae': make_scorer(mean_absolute_error),\n",
    "#                'mse': make_scorer(mean_squared_error, greater_is_better=False)\n",
    "#     }\n",
    "\n",
    "# returns best model according to scorring metrics\n",
    "cv_model = GridSearchCV(pipeline, \n",
    "                        param_grid = param_dist, \n",
    "                        scoring = scorer, \n",
    "                        cv = 5, \n",
    "                        verbose=5,\n",
    "                        return_train_score = True\n",
    ")\n",
    "cv_model.fit(x_train, y_train)\n",
    "# cv_model.get_params().keys()\n",
    "\n",
    "best_model = cv_model.best_estimator_\n",
    "best_params = cv_model.best_params_\n",
    "cv_results = cv_model.cv_results_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "preds_train = best_model.predict(x_train)\n",
    "preds_test = best_model.predict(x_test)\n",
    "\n",
    "# Merge the predictions back onto the original DF\n",
    "listings['preds'] = np.hstack([preds_train, preds_test])\n",
    "listings['preds'] = round(listings['preds'], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance & Evaluation\n",
    "--------------\n",
    "\n",
    "Time allocated should be ~15 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score=cross_val_score(best_model, \n",
    "                         listings[num_cols + cat_cols_indx], \n",
    "                         listings['price'], \n",
    "                         cv=5, \n",
    "                         scoring=make_scorer(mean_absolute_error), \n",
    "                         n_jobs=-1).mean()\n",
    "\n",
    "print(\"MAE:  \", round(mean_absolute_error(y_test, preds_test), 2))\n",
    "print(\"MSE:  \", round(mean_squared_error(y_test, preds_test), 2))\n",
    "print(\"RMSE: \", round(sqrt(metrics.mean_squared_error(y_test, preds_test)), 2))\n",
    "print(\"R2:   \", round(r2_score(y_test, preds_test),2))\n",
    "print(\"Cross-Validation Score: \", cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.Series({f:v for v, f in zip(best_model[1].feature_importances_, x_train.columns)})\n",
    "feat_imp.nlargest(30)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "              x=feat_imp[:20],\n",
    "              y=feat_imp.index[:20],\n",
    "              name='Feature Importances',\n",
    "              orientation='h',\n",
    "              marker_color=plotly.colors.sequential.Rainbow[4]\n",
    "))\n",
    "\n",
    "fig.update_layout(title='Feature Importances', \n",
    "                  xaxis_tickangle=-45,\n",
    "                  xaxis_title=\"Importance\",\n",
    "                  yaxis_title=\"Feature Name\",\n",
    "                  autosize=False,\n",
    "                  height=1000,\n",
    "                  width=1000,\n",
    "                  yaxis={'categoryorder':'total ascending'}\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Curves for assessing model fit for hyperparameters\n",
    "\n",
    "train_scores, test_scores = validation_curve(best_model, \n",
    "                                             listings[num_cols + cat_cols_indx], \n",
    "                                             listings['price'], \n",
    "                                             param_name = \"regressor__n_estimators\", \n",
    "                                             param_range = [num for num in range(10, 200, 20)],\n",
    "                                             scoring=scorer\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "              x=[num for num in range(10, 200, 20)],\n",
    "              y=[np.mean(fold) for fold in train_scores],\n",
    "              name='Train MAE',\n",
    "              mode='lines+markers',\n",
    "              marker_color=plotly.colors.sequential.Jet[2]\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "              x=[num for num in range(10, 200, 20)],\n",
    "              y=[np.mean(fold) for fold in test_scores],\n",
    "              name='Test MAE',\n",
    "              mode='lines+markers',\n",
    "              marker_color=plotly.colors.sequential.Jet[4]\n",
    "))\n",
    "\n",
    "fig.update_layout(title='Validation Curve: Number of Estimators', \n",
    "                  xaxis_tickangle=-45,\n",
    "                  xaxis_title=\"Number of Estimators\",\n",
    "                  yaxis_title=\"CV MAE\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:datascience] *",
   "language": "python",
   "name": "conda-env-datascience-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
